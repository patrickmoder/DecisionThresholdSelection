{{ extends 'global/Page.html' }}
{{ block title }}Introduction to Misclassification Costs{{ endblock }}

{{ block content }}

<!--<p>
    In general, one tries to make as many correct classifications as possible: we can calculate the <b>accuracy</b> of an algorithm by dividing the total number of correct classifications (TP+TN) by the total number of samples.
    The accuracy is a number between 0 and 1, with higher values indicating more accurate classifications. <br />
</p>-->

<p>
    In our setting, we assume that correct predictions are equally valuable.
    Yet, when making incorrect predictions of machine breakdowns, we expect misclassification costs.
    Such misclassification costs can vary and depend on the environment where the AI algorithm is applied:
    <ul>
        <li>After False Alarms, one might start unnecessary maintenance activities and suffer from unnecessary down-times of machines.</li>
        <li>After Missed Hits, one might lose the opportunity to prevent the breakdown and suffer from avoidable down-times of machines.</li>
    </ul>
</p>

<p>
    Let us illustrate these considerations in an example:
    in the training set that is used to train the AI algorithm, out of a sample of 20 machines, 10 break down in the next 48 hours and 10 machines do not break down.
    In our example, we assume misclassification costs of 5 cost units for each False Alarm and 1 cost unit for each Missed Hit, respectively.
    <br />
    Now, let us assume that we choose a decision threshold D of 0.65, which determines that above a likelihood of 0.65, we predict a machine to breakdown.
    With D = 0.65, the predictions by the AI algorithm for the 20 machines in the training set (also displayed in the matrix below) are as follows:
    <ul>
        <li>13 correct predictions: 6 Correct Predictions of Breakdown, 7 Correct Predictions of No Breakdown</li>
        <li>7 incorrect predictions: 3 False Alarms and 4 Missed Hits</li>
</ul>
</p>

<table id="confusionmatrix" cellpadding="4px" border="1px">
    <caption align="right">Prediction Outcomes</caption>
    <thead>
        <tr>
            <th></th>
            <th></th>
            <th colspan="2">Predicted State</th>
        </tr>
    </thead>
    <tbody>
        <tr>
           <td></td>
           <td></td>
           <td>Breakdown</td>
           <td>No Breakdown</td>
       </tr>
       <tr>
           <td rowspan="2"><b>Actual State</b></td>
           <td>Breakdown</td>
           <td id="tp" style="color:green">6</td>
           <td id ="fn" style="color:red">4</td>
       </tr>
       <tr>
           <td>No Breakdown</td>
           <td id ="fp" style="color:red">3</td>
           <td id ="tn" style="color:green">7</td>
       </tr>
    </tbody>
</table>

<p>
    <!--Our chosen threshold D results in a prediction accuracy of 0.65 (13 correct classifications out of 20 objects in total).-->
    Consequently, on our training set we would expect misclassification costs of 3 x 5 cost units (=15 cost units) for False Alarms and 4 x 1 cost unit (=4 cost units) for Missed Hits, resulting in 19 cost units overall.
</p>

<!--<table id="costmatrix" cellpadding="4px" border="1px">
    <caption align="right">Cost Matrix (Absolute Misclassification Costs [$])</caption>
    <thead>
        <tr>
            <th></th>
            <th></th>
            <th colspan="2">Predicted Class</th>
        </tr>
    </thead>
    <tbody>
        <tr>
           <td></td>
           <td></td>
           <td>Positive</td>
           <td>Negative</td>
       </tr>
       <tr>
           <td rowspan="2"><b>Actual Class</b></td>
           <td>Positive</td>
           <td> - </td>
           <td id ="fnc">4</td>
       </tr>
       <tr>
           <td>Negative</td>
           <td id ="fpc">15</td>
           <td> - </td>
       </tr>
    </tbody>
</table>-->


{{ next_button }}

{{ endblock }}

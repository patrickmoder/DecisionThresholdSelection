{{ extends 'global/Page.html' }}
{{ block title }}Introduction to Misclassification Costs{{ endblock }}

{{ block content }}

<p>
    In general, one tries to make as many correct classifications as possible: we can calculate the <b>accuracy</b> of an algorithm by dividing the total number of correct classifications (TP+TN) by the total number of samples.
    The accuracy is a number between 0 and 1, with higher values indicating more accurate classifications. <br />
    When making an incorrect classifications (FP or FN), we also expect <b>misclassification costs</b>.
    Such misclassification costs can be different for False Positive (FP) and False Negative (FN) classifications.
    Both the accuracy and the misclassification costs are affected by the selected decision threshold D.
</p>

<p>
    Let us illustrate these considerations in an example: imagine a well-trained AI algorithm that predicts which class (positive or negative) an object belongs to.
    Out of a set of 20 objects, 10 objects belong to the positive and 10 objects belong to the negative class.
    In our example, we assume misclassification costs of 5$ for each False Positive (FP) classification and 1$ for each False Negative (FN) classification, respectively.
    Now, let us assume that we choose a decision threshold D, with which the classifications by the AI algorithm are the following (also displayed in the confusion matrix below):
    <ul>
        <li>13 correct classifications: 6 True Positives, 7 True Negatives</li>
        <li>7 incorrect classifications: 3 False Positives and 4 False Negatives</li>
</ul>
</p>

<table id="confusionmatrix" cellpadding="4px" border="1px">
    <caption align="right">Confusion Matrix (Absolute Classification Outcomes)</caption>
    <thead>
        <tr>
            <th></th>
            <th></th>
            <th colspan="2">Predicted Class</th>
        </tr>
    </thead>
    <tbody>
        <tr>
           <td></td>
           <td></td>
           <td>Positive</td>
           <td>Negative</td>
       </tr>
       <tr>
           <td rowspan="2"><b>Actual Class</b></td>
           <td>Positive</td>
           <td id="tp" style="color:green">6</td>
           <td id ="fn" style="color:red">4</td>
       </tr>
       <tr>
           <td>Negative</td>
           <td id ="fp" style="color:red">3</td>
           <td id ="tn" style="color:green">7</td>
       </tr>
    </tbody>
</table>

<p>
    Our chosen threshold D results in a prediction accuracy of 0.65 (13 correct classifications out of 20 objects in total).
    Moreover, we would expect misclassification costs of 3 x 5$ (=15$) for False Positive classifications and 4 x 1$ (=4$) for False Negative classifications, resulting in 19$ overall.
    We display the overall misclassification costs in the "cost matrix" below.
</p>

<table id="costmatrix" cellpadding="4px" border="1px">
    <caption align="right">Cost Matrix (Absolute Misclassification Costs [$])</caption>
    <thead>
        <tr>
            <th></th>
            <th></th>
            <th colspan="2">Predicted Class</th>
        </tr>
    </thead>
    <tbody>
        <tr>
           <td></td>
           <td></td>
           <td>Positive</td>
           <td>Negative</td>
       </tr>
       <tr>
           <td rowspan="2"><b>Actual Class</b></td>
           <td>Positive</td>
           <td> - </td>
           <td id ="fnc">4</td>
       </tr>
       <tr>
           <td>Negative</td>
           <td id ="fpc">15</td>
           <td> - </td>
       </tr>
    </tbody>
</table>


{{ next_button }}

{{ endblock }}
